{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PSL Live Recognition.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saman-Karim/PSL-translator/blob/main/PSL_Live_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-XevuXKvjQ5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETm-CDkr0mC6"
      },
      "source": [
        "!unzip '/content/drive/MyDrive/PSL_video/train.zip'\n",
        "!unzip '/content/drive/MyDrive/PSL_video/validation.zip'\n",
        "!unzip '/content/drive/MyDrive/PSL_video/test.zip'\n",
        "\n",
        "# PSL Train, Validation and Test dataset is available at https://drive.google.com/drive/folders/1_-HvCXLZXSGESzYy8a7MFFJumPgYDhz5?usp=sharing \n",
        "# Developed Xception Model (model.json, model-weights.h5) is available at https://drive.google.com/drive/folders/1A3cVF7I6h0MLk8JVdI_OCHLMyEePYje5?usp=sharing"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gqZjW8e1Vcr"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "import pandas as pd\n",
        "import json\n",
        "from skimage import transform\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.applications import InceptionV3, Xception, InceptionResNetV2\n",
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from keras.applications.mobilenet import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.models import model_from_json\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0NKVJoy1bci"
      },
      "source": [
        "TRAINING_DATA_SET_PATH = '/content/train'\n",
        "VALIDATION_DATA_SET_PATH = '/content/validation'\n",
        "TEST_DATA_SET_PATH = '/content/test'\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 32\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_WIDTH = 224\n",
        "DATASET_CATEGORIES = 27\n",
        "\n",
        "def loadModelfromJson(modelPath, weightPath):\n",
        "    json_file = open(modelPath, 'r')\n",
        "    loaded_model_json = json_file.read()\n",
        "    json_file.close()\n",
        "\n",
        "    loaded_model = model_from_json(loaded_model_json)\n",
        "\n",
        "    loaded_model.load_weights(weightPath)\n",
        "    print(\"Model loaded from\", modelPath)\n",
        "    return loaded_model\n",
        "\n",
        "\n",
        "def loadSingleImage(filename):\n",
        "    np_image = Image.open(filename)\n",
        "    np_image = np.array(np_image).astype('float32')\n",
        "    img = img/255\n",
        "    np_image = transform.resize(np_image, (IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "    np_image = np.expand_dims(np_image, axis=0)\n",
        "    return np_image\n",
        "\n",
        "def load_image(img_path, show=False):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(IMAGE_HEIGHT, IMAGE_WIDTH))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "\n",
        "\n",
        "def showImageCV(preds, imagePath, letter):\n",
        "    # find the class label index with the largest corresponding\n",
        "    # probability\n",
        "    i = preds.argmax(axis=1)[0]\n",
        "    # label = lb.classes_[i]\n",
        "    # draw the class label + probability on the output image\n",
        "    text = \"{}: {:.2f}%\".format(letter, preds[0][i] * 100)\n",
        "\n",
        "    image = cv2.imread(imagePath)\n",
        "    output = image.copy()\n",
        "    cv2.putText(output, text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,\n",
        "                (0, 0, 255), 2)\n",
        "    # show the output image\n",
        "    cv2_imshow(output)\n",
        "    cv2.waitKey(0)\n",
        "\n",
        "\n",
        "def getTopPredictions(preds):\n",
        "    predsDict = {  \n",
        "       'Aliph': 0, 'Aliph_mad_aa':0, 'Bari_yeh': 0, 'Bay':0, 'Choti_yeh': 0, 'Daal': 0, 'Fay':0, 'Ghain': 0, 'Hey': 0, \n",
        "       'Jeem':0, 'Kaaf':0, 'Laam': 0, 'Meem':0, 'Noon':0, 'Pay':0, 'Quaaf': 0, 'Ray':0, 'Say':0,\n",
        "       'Seen':0, 'Tey':0, 'Vao':0, 'Zaal':0, 'Zay': 0, 'aRay':0, 'del':0, 'nothing':0, 'space': 0,         \n",
        "    }\n",
        "\n",
        "    # map preds index with probability to correct letter from dictonary\n",
        "    for i, key in enumerate(predsDict, start=0):\n",
        "        predsDict[key] = preds[i]\n",
        "\n",
        "    # sort by dictonary value and returns as list\n",
        "    all_preds = sorted(predsDict.items(), reverse=True, key=lambda x: x[1])\n",
        "\n",
        "    top_preds = [all_preds[0], all_preds[1], all_preds[2]]\n",
        "    return top_preds, all_preds\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rrvPUtMizTH"
      },
      "source": [
        "def predictSingleImage(filepath, model):\n",
        "    inputImage = Image.open(filepath)\n",
        "    inputImage = inputImage.resize((224, 224))\n",
        "\n",
        "    imageDataArray = image.img_to_array(inputImage)\n",
        "    imageDataArray = np.expand_dims(imageDataArray, axis=0)\n",
        "    imageDataArray = preprocess_input(imageDataArray)\n",
        "\n",
        "    predictions = model.predict(imageDataArray)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSiz7xchue4-"
      },
      "source": [
        "finalModel = loadModelfromJson('/content/drive/MyDrive/output/model.json', '/content/drive/MyDrive/output/model-weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1_p5s00kKnK"
      },
      "source": [
        "# import dependencies\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjPhzvIOj-j6"
      },
      "source": [
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "055t3HYwnhBh"
      },
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "    \n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "    \n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "    \n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "    \n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "      \n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"<span>Status:</span>\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      labelElement.style.color = 'red';\n",
        "      labelElement.style.size = '32px';\n",
        "\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "           \n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "      \n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML = \n",
        "          '<span style=\"color: black; font-weight: bold;\">' +\n",
        "          'Real time PSL Recognition</span>';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "      \n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "      \n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "      \n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "            \n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "      \n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "      \n",
        "      return {'create': preShow - preCreate, \n",
        "              'show': preCapture - preShow, \n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "  \n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7mCUFIjnjxu"
      },
      "source": [
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0\n",
        "\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    #cv2_imshow(img)\n",
        "\n",
        "    try:\n",
        "      #img2 = cv2.flip(img, 1)\n",
        "      np_image = transform.resize(img, (IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
        "      np_image = np.expand_dims(np_image, axis=0)\n",
        "      #image1 = load_image(filename)\n",
        "      predictions = finalModel.predict(np_image)\n",
        "      top_three_preds, all_preds = getTopPredictions(predictions[0])\n",
        "\n",
        "      if (top_three_preds[0][1] > 0.7):\n",
        "        label_html = \"{}: {:.2f}%\".format(top_three_preds[0][0], top_three_preds[0][1] * 100)\n",
        "      else:\n",
        "        label_html = \"Capturing...\"\n",
        "\n",
        "    # show the output image\n",
        "      #cv2_imshow(img2)\n",
        "\n",
        "\n",
        "    except Exception as err:\n",
        "      # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "      # grant the page permission to access it.\n",
        "      print(str(err))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Live recognition code inspired by: https://www.youtube.com/watch?v=YjWh7QvVH60\n"
      ],
      "metadata": {
        "id": "Qj1dEeSIX2XB"
      }
    }
  ]
}